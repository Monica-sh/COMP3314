{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COMP3314 ML\n",
    "Guo Shunhua 3035447635 \n",
    "<br>\n",
    "# <u>Logistic regression Construction</u>\n",
    "\n",
    "## Overview\n",
    "1. [Introduction](#s1) \n",
    "2. [Decision Tree](#s2)\n",
    "3. [Random Forest](#s3)\n",
    "4. [Load data & Apply the model](#s4) \n",
    "5. [Plotting the result for analysis](#s5)\n",
    "6. [Parameter Analysis](#s6)\n",
    "\n",
    "\n",
    "----- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=’s1’></a>\n",
    "\n",
    "## 1 Introduction\n",
    "\n",
    "This notebook will implement a Multi-class Decision Tree, Random Forest, and then train implemented model to provided data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=’s2’></a>\n",
    "\n",
    "## 2 Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Import Libraries</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if sys.version_info[0] < 3:\n",
    "    raise Exception(\"Python 3 not detected\")\n",
    "                    \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "import statistics\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As stated in the lecture, the following impurity measures or splitting criteria are commonly used in decision trees:\n",
    "1. Gini impurity ( gini ), \n",
    "2. Entropy ( entropy ), \n",
    "3. Classification error ( classificationError )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 0.0\n"
     ]
    }
   ],
   "source": [
    "# define gini value for one group (classes)\n",
    "def gini(group, numClass):\n",
    "    gini = 1  \n",
    "    size = len(group)\n",
    "    \n",
    "    if size != 0:\n",
    "        y_v = [y[-1] for y in group]\n",
    "        for c in range(numClass):\n",
    "            #proportion of each class\n",
    "            p = y_v.count(c)/size\n",
    "            gini -= p**2\n",
    "\n",
    "    return gini \n",
    "print(gini([[1, 1], [1, 0]], 2), gini([[1, 0], [1, 0]], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n"
     ]
    }
   ],
   "source": [
    "# define entropy value for one group (classes)\n",
    "def entropy(group, numClass):\n",
    "    entropy = 0  \n",
    "    size = len(group)\n",
    "    \n",
    "    if size != 0:\n",
    "        y_v = [y[-1] for y in group]\n",
    "        for c in range(numClass):\n",
    "            #proportion of each class\n",
    "            p = y_v.count(c)/size\n",
    "            entropy -= p * math.log(p,2)\n",
    "\n",
    "    return entropy \n",
    "print(entropy([[1, 1], [1, 0]], 2), gini([[1, 0], [1, 0]], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 0.0\n"
     ]
    }
   ],
   "source": [
    "# define classificationError value for one group (classes)\n",
    "def classificationError(group, numClass):\n",
    "    p = []\n",
    "    size = len(group)\n",
    "    \n",
    "    if size != 0:\n",
    "        y_v = [y[-1] for y in group]\n",
    "        for c in range(numClass):\n",
    "            #proportion of each class\n",
    "            p.append(y_v.count(c)/size)\n",
    "\n",
    "    e = 1 - np.max(p)     \n",
    "    return e \n",
    "print(classificationError([[1, 1], [1, 0]], 2), gini([[1, 0], [1, 0]], 2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct a split\n",
    "def split(group, x_index, val):\n",
    "    #record group spliting result\n",
    "    left = []\n",
    "    right = []\n",
    "    for x in group:\n",
    "        if x[x_index] < val:\n",
    "            left.append(x)\n",
    "        else:\n",
    "            right.append(x)\n",
    "    return left, right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute information gain at a split point\n",
    "def info_gain(group, x_index, val, numClass):\n",
    "    size = len(group)\n",
    "    #parent's loss\n",
    "    p = gini(group, numClass)\n",
    "    \n",
    "    left, right = split(group, x_index, val)\n",
    "    \n",
    "    # proportional left/right group's loss\n",
    "    l = gini(left, numClass) * len(left) / size\n",
    "    r = gini(right, numClass) * len(right) / size\n",
    "    \n",
    "    return p-l-r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select split\n",
    "def select_split(group, numClass):\n",
    "    info_gain_v = []\n",
    "    info_gain_comb = []\n",
    "    for x_index in range(len(group[0])-1):\n",
    "        if len(group) > 100:   \n",
    "            x = [x[x_index] for x in group]\n",
    "            xmin, xmax = np.min(x), np.max(x)\n",
    "            step_size = (xmax - xmin)/20\n",
    "            val = xmin + step_size\n",
    "            while val < xmax:\n",
    "                ig = info_gain(group, x_index, val, numClass)\n",
    "                #print(\"x_index: %f; val: %f; ig: %f\" % (x_index, val, ig))\n",
    "\n",
    "                info_gain_v.append(ig)\n",
    "                info_gain_comb.append([x_index, val])\n",
    "                val += step_size\n",
    "        \n",
    "        else:\n",
    "            for x in group:\n",
    "                ig = info_gain(group, x_index, x[x_index], numClass)\n",
    "                #print(\"x_index: %f; val: %f; ig: %f\" % (x_index, x[x_index], ig))\n",
    "\n",
    "                info_gain_v.append(ig)\n",
    "                info_gain_comb.append([x_index, x[x_index]])\n",
    "\n",
    "    # get the split resulting maximum infomation gain\n",
    "    x_index, val = info_gain_comb[np.argmax(info_gain_v)]\n",
    "    print(\"FINAL: x_index: %f; val: %f\" % (x_index, val))\n",
    "    return split(group, x_index, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL: x_index: 0.000000; val: 6.642287\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([[2.771244718, 1.784783929, 0],\n",
       "  [1.728571309, 1.169761413, 0],\n",
       "  [3.678319846, 2.81281357, 0],\n",
       "  [3.961043357, 2.61995032, 0],\n",
       "  [2.999208922, 2.209014212, 0]],\n",
       " [[7.497545867, 3.162953546, 1],\n",
       "  [9.00220326, 3.339047188, 1],\n",
       "  [7.444542326, 0.476683375, 1],\n",
       "  [10.12493903, 3.234550982, 1],\n",
       "  [6.642287351, 3.319983761, 1]])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = [[2.771244718,1.784783929,0],\n",
    "\t[1.728571309,1.169761413,0],\n",
    "\t[3.678319846,2.81281357,0],\n",
    "\t[3.961043357,2.61995032,0],\n",
    "\t[2.999208922,2.209014212,0],\n",
    "\t[7.497545867,3.162953546,1],\n",
    "\t[9.00220326,3.339047188,1],\n",
    "\t[7.444542326,0.476683375,1],\n",
    "\t[10.12493903,3.234550982,1],\n",
    "\t[6.642287351,3.319983761,1]]\n",
    "select_split(dataset, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X input Meaning:  buying price, price of the maintenance, number of doors,  number of persons to carry, size of luggage boot, safety of the car\n",
      "X training Class List:  {'high', 'low', '3', 'small', 'med', 'vhigh', 'more', 'big', '5more', '2', '4'}\n",
      "y training Class List:  {'acc', 'good', 'unacc', 'vgood'}\n",
      "X test Class List:  {'high', 'low', 'small', '3', 'med', 'vhigh', 'more', 'big', '5more', '2', '4'}\n",
      "y test Class List:  {'acc', 'good', 'unacc', 'vgood'}\n"
     ]
    }
   ],
   "source": [
    "# Load raw data from csv file, which located in the same folder as this notebook.\n",
    "\n",
    "X_train_raw = pd.read_csv(\"dataset_files/car_X_train.csv\").to_numpy()\n",
    "y_train_raw = pd.read_csv(\"dataset_files/car_y_train.csv\").to_numpy()\n",
    "X_test_raw = pd.read_csv(\"dataset_files/car_X_test.csv\").to_numpy()\n",
    "y_test_raw = pd.read_csv(\"dataset_files/car_y_test.csv\").to_numpy()\n",
    "\n",
    "print(\"X input Meaning: \",\n",
    "      \"buying price, price of the maintenance, number of doors, \",\n",
    "      \"number of persons to carry, size of luggage boot, safety of the car\")\n",
    "\n",
    "print(\"X training Class List: \", set(X_train_raw.flatten()))\n",
    "print(\"y training Class List: \", set(y_train_raw.flatten()))\n",
    "print(\"X test Class List: \", set(X_test_raw.flatten()))\n",
    "print(\"y test Class List: \", set(y_test_raw.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform str indicators in data to numeric classes\n",
    "x_dict = {\n",
    "    'vhigh' : 4, \n",
    "    'high' : 3,\n",
    "    'med' : 2,\n",
    "    'low' : 1, \n",
    "     \n",
    "    'small' : 1,\n",
    "    # 'med' : 2,\n",
    "    'big' : 3,\n",
    "    \n",
    "    # '2' : 2, \n",
    "    # '4' : 4,\n",
    "    'more' : 6, \n",
    "    \n",
    "    '2' : 2, \n",
    "    '3' : 3,\n",
    "    '4' : 4,\n",
    "    '5more' : 6,\n",
    "}\n",
    "\n",
    "y_dict = {\n",
    "    'acc':1, 'good':2, 'unacc':0, 'vgood':3\n",
    "}\n",
    "\n",
    "def transform_X(X):\n",
    "    for i in range(len(X)):\n",
    "        x = X[i]\n",
    "        X[i] = [x_dict[i] for i in x]\n",
    "    return X\n",
    "\n",
    "def transform_y(y):\n",
    "    return [[y_dict[row[0]]] for row in y]\n",
    "\n",
    "X_train = transform_X(X_train_raw)\n",
    "y_train = np.array(transform_y(y_train_raw))\n",
    "X_test = transform_X(X_test_raw)\n",
    "y_test = np.array(transform_y(y_test_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DTnode(object):\n",
    "    def __init__(self, level=0):\n",
    "        self.level = level\n",
    "        \n",
    "        self.x_index = None\n",
    "        self.val = None\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        \n",
    "    def update_info(self, x_index, val, left, right):\n",
    "        self.x_index = x_index\n",
    "        self.val = val\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        \n",
    "    def add_class(self, c):\n",
    "        # print(\"add c, c = \", c)\n",
    "        self.c = c\n",
    "        \n",
    "    def get_info(self):\n",
    "        return self.x_index, self.val, self.left, self.right\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree(object):\n",
    "    def __init__(self, criterion='gini', max_depth=4, min_size=1):\n",
    "        self.criterion = criterion\n",
    "        self.max_depth = max_depth\n",
    "        self.min_size = min_size\n",
    "    \n",
    "    # main function for training the model\n",
    "    def fit(self, X, y):\n",
    "        self.numClass = int(np.max(y)) + 1\n",
    "        X_w_y = np.concatenate((X, y), axis = 1)\n",
    "        \n",
    "        # gives a group split with max_depth\n",
    "        # record each node spliting\n",
    "        self.root = DTnode()\n",
    "        self.split_node(self.root, X_w_y, self.max_depth)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    #recursively split the group\n",
    "    def split_node(self, node, group, max_depth):\n",
    "        if len(group) == 0:\n",
    "            return\n",
    "        \n",
    "        if max_depth <= 0 or len(group) <= self.min_size:\n",
    "            y_v = [y[-1] for y in group]\n",
    "            c_v = [y_v.count(c) for c in range(self.numClass)]\n",
    "            c = np.argmax(c_v)\n",
    "            node.add_class(c)\n",
    "            return \n",
    "        \n",
    "        (left, right), x_index, val = self.select_split(group)\n",
    "        leftnode = DTnode(level=node.level+1)\n",
    "        rightnode = DTnode(level=node.level+1)\n",
    "        node.update_info(x_index, val, leftnode, rightnode)\n",
    "        \n",
    "        self.split_node(leftnode, left, max_depth-1)\n",
    "        self.split_node(rightnode, right, max_depth-1)\n",
    "    \n",
    "    # predict single x input\n",
    "    def predict(self, node, x):\n",
    "        x_index, val, leftnode, rightnode = node.get_info()\n",
    "        \n",
    "        if x_index == None or val == None:\n",
    "            return node.c\n",
    "        elif x[x_index] < val:\n",
    "            return self.predict(leftnode, x)\n",
    "        else:\n",
    "            return self.predict(rightnode, x)\n",
    "    \n",
    "    #compute model accuracy\n",
    "    def accuracy(self, X, y):\n",
    "        y_pred = [[self.predict(self.root, x)] for x in X]\n",
    "        return (y_pred == y).sum()/len(y)\n",
    "            \n",
    "    # select split\n",
    "    def select_split(self, group):\n",
    "        info_gain_v = []\n",
    "        info_gain_comb = []\n",
    "        for x_index in range(len(group[0])-1):\n",
    "            if len(group) > 100:   \n",
    "                x_v = [x[x_index] for x in group]\n",
    "                xmin, xmax = np.min(x_v), np.max(x_v)\n",
    "                step_size = (xmax - xmin)/20\n",
    "                val = xmin + step_size\n",
    "                while val < xmax:\n",
    "                    ig = info_gain(group, x_index, val, self.numClass)\n",
    "                    #print(\"x_index: %f; val: %f; ig: %f\" % (x_index, val, ig))\n",
    "\n",
    "                    info_gain_v.append(ig)\n",
    "                    info_gain_comb.append([x_index, val])\n",
    "                    val += step_size\n",
    "\n",
    "            else:\n",
    "                for x in group:\n",
    "                    ig = info_gain(group, x_index, x[x_index], self.numClass)\n",
    "                    #print(\"x_index: %f; val: %f; ig: %f\" % (x_index, x[x_index], ig))\n",
    "\n",
    "                    info_gain_v.append(ig)\n",
    "                    info_gain_comb.append([x_index, x[x_index]])\n",
    "\n",
    "        # get the split resulting maximum infomation gain\n",
    "        x_index, val = info_gain_comb[np.argmax(info_gain_v)]\n",
    "        # print(\"FINAL: x_index: %i; val: %f\" % (x_index, val))\n",
    "        return split(group, x_index, val), x_index, val    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy:  0.8709677419354839\n",
      "test accuracy:  0.8420038535645472\n"
     ]
    }
   ],
   "source": [
    "tree = DecisionTree()\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "print(\"training accuracy: \", tree.accuracy(X_train, y_train))\n",
    "print(\"test accuracy: \", tree.accuracy(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest(object):\n",
    "    def __init__(self, criterion='gini', max_depth=4, min_size=1, \n",
    "                 k_estimators=25, random_seed=42):\n",
    "        \n",
    "        self.criterion = criterion\n",
    "        self.max_depth = max_depth\n",
    "        self.min_size = min_size\n",
    "        self.k_estimators = k_estimators\n",
    "        self.random_seed = random_seed\n",
    "\n",
    "    # main function for training the model\n",
    "    def fit(self, X, y, n_sample_size=None, d_features=None):\n",
    "        \n",
    "        # define n sample size if not yet defined\n",
    "        if n_sample_size == None:\n",
    "            self.n_sample_size = int(len(y)/10)\n",
    "        else:\n",
    "            self.n_sample_size = sample_size\n",
    "        \n",
    "        # define d feature number if not yet defined\n",
    "        if d_features == None:\n",
    "            self.d_features = len(X[0])\n",
    "        else:\n",
    "            self.d_features = d_features\n",
    "        \n",
    "        self.trees = []\n",
    "        for i in range(self.k_estimators):\n",
    "            #set random seed\n",
    "            random.seed(int(self.n_sample_size))\n",
    "            self.n_sample_size += 1\n",
    "            rnd_index = random.sample(range(len(y)), self.n_sample_size)\n",
    "            X_sampled = X[rnd_index]\n",
    "            y_sampled = y[rnd_index]\n",
    "            self.trees.append(self.return_DT(X_sampled, y_sampled))\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def return_DT(self, X_sampled, y_sampled):\n",
    "        tree = DecisionTree(criterion=self.criterion, \n",
    "                            max_depth=self.max_depth, min_size=self.min_size)\n",
    "        return tree.fit(X_sampled, y_sampled)\n",
    "        \n",
    "    #predict single x sample\n",
    "    def predict(self, x):\n",
    "        y_preds = [tree.predict(tree.root, x) for tree in self.trees]\n",
    "        return statistics.mode(y_preds)\n",
    "    \n",
    "    # calculate accuracy of the model\n",
    "    def accuracy(self, X, y):\n",
    "        y_pred = [[self.predict(x)] for x in X]\n",
    "        return (y_pred == y).sum()/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy:  0.8577336641852771\n",
      "test accuracy:  0.8670520231213873\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForest()\n",
    "forest.fit(X_train, y_train)\n",
    "\n",
    "print(\"training accuracy: \", forest.accuracy(X_train, y_train))\n",
    "print(\"test accuracy: \", forest.accuracy(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
