{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COMP3314 ML\n",
    "Guo Shunhua 3035447635 \n",
    "<br>\n",
    "# <u>Logistic regression Construction</u>\n",
    "\n",
    "## Overview\n",
    "1. [Introduction](#s1) \n",
    "2. [Logistic regression Model Setup](#s2) \n",
    "3. [Load data & Apply the model](#s3) \n",
    "4. [Plotting the result for analysis](#s4)\n",
    "5. [Parameter Analysis](#s5)\n",
    "\n",
    "\n",
    "----- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=’s1’></a>\n",
    "\n",
    "## 1 Introduction\n",
    "\n",
    "This notebook will implement a Multi-class Logistic regression and then train implemented model to provided data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=’s2’></a>\n",
    "\n",
    "## 2 Logistic regression Model Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Import Libraries</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if sys.version_info[0] < 3:\n",
    "    raise Exception(\"Python 3 not detected\")\n",
    "                    \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the sigmoid function applies to binary classification cases while the softmax function applies to multi-class classification problems, I will implement softmax function first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.03205860328008499,\n",
       " 0.08714431874203257,\n",
       " 0.23688281808991013,\n",
       " 0.6439142598879722]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def softmax(x):\n",
    "    \"\"\"\n",
    "    input: x as a vector\n",
    "    output: a vector\n",
    "    \"\"\"\n",
    "    x_exp = [np.exp(i) for i in x]\n",
    "    x_exp_sum = sum(x_exp)\n",
    "    return [i / x_exp_sum for i in x_exp]\n",
    "\n",
    "x = [1, 2, 3, 4]\n",
    "softmax(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiclass Logistic Regression Model Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionMulti(object):\n",
    "    def __init__(self, learning_rate=0.05, n_iter=1000,\n",
    "                 regularization_param=0.01, regularization=2, validation=None):\n",
    "        self.l = learning_rate\n",
    "        self.n_iter = n_iter\n",
    "        # 0 = no regularization\n",
    "        # 1 = L1\n",
    "        # 2 = L2 (default)\n",
    "        self.regularization = regularization\n",
    "        self.r = regularization_param\n",
    "        \n",
    "        # if None, then no validation set used\n",
    "        self.validation = validation\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        numClass = int(np.max(y)) + 1\n",
    "        # weight vector include the intercept term\n",
    "        self.w = np.random.rand(X.shape[1] + 1, numClass)\n",
    "        self.cost = []\n",
    "        self.cost_val = []\n",
    "        self.accu = []\n",
    "        self.accu_val = []\n",
    "        \n",
    "        if self.validation != None:\n",
    "            if self.validation < len(y):\n",
    "                X_val = X[self.validation:]\n",
    "                y_val = y[self.validation:]\n",
    "                X = X[:self.validation]\n",
    "                y = y[:self.validation]\n",
    "            else:\n",
    "                print(\"validation number input is larger than the data length\")\n",
    "                self.validation = None\n",
    "        \n",
    "        for i in range(self.n_iter):\n",
    "            net_input = self.net_input(X)\n",
    "            output = self.activation(net_input)\n",
    "            \n",
    "            #gredient decend \n",
    "            grad = self.gradient(output, X, y)\n",
    "#             print(self.w)\n",
    "#             print(grad)\n",
    "#             print(self.w - self.l * grad)\n",
    "            self.w = self.w - self.l * grad\n",
    "            \n",
    "            if self.regularization == 1:\n",
    "                self.w -= self.r * np.sign(self.w)\n",
    "            elif self.regularization == 2:\n",
    "                self.w -= self.r * self.w\n",
    "            \n",
    "            # loss function\n",
    "            loss = self.loss(output, y)\n",
    "            self.cost.append(loss)\n",
    "            \n",
    "            # accuracy \n",
    "            self.accu.append(self.accuracy(X, y))\n",
    "            \n",
    "            # loss and accuracy for validation set \n",
    "            if self.validation != None:\n",
    "                output_val = self.activation(self.net_input(X_val))\n",
    "                self.cost_val.append(self.loss(output_val, y_val))\n",
    "                self.accu_val.append(self.accuracy(X_val, y_val))\n",
    "                \n",
    "        return self\n",
    "    \n",
    "    def net_input(self, X):\n",
    "        return np.matmul(X, self.w[1:]) + self.w[0]\n",
    "    \n",
    "    def activation(self, z):\n",
    "        # softmax for multi-class\n",
    "        return [softmax(i) for i in z]\n",
    "    \n",
    "    def gradient(self, output, X, y):\n",
    "        # output the gradient for weight vector\n",
    "        # shape is the same as weight vector\n",
    "        grad = [self.compute_gradients(output[i], X[i], y[i]) for i in range(len(y))]\n",
    "        gradient = np.reshape(np.mean(grad, axis=0), (X.shape[1] + 1, len(output[0])))\n",
    "        return gradient\n",
    "\n",
    "    #calculate gradient for single data point as flattened\n",
    "    def compute_gradients(self, out, x, y):\n",
    "        out = np.reshape(out, (len(out), 1))\n",
    "        out[y] = out[y]-1\n",
    "        x = np.append(np.array(1), x)\n",
    "        grad = out * x\n",
    "        return grad.transpose().flatten()\n",
    "\n",
    "    def loss(self, output, y):\n",
    "        loss = sum([-np.log(output[i][int(y[i])]) for i in range(len(y))])\n",
    "        \n",
    "        if self.regularization == 1:\n",
    "            loss += self.r * np.sum(np.abs(self.w))\n",
    "        elif self.regularization == 2:\n",
    "            loss += 0.5 * self.r * np.sum(self.w**2) \n",
    "        #return sum([-np.log(output[i][int(y[i])]) + 0.5*self.r*np.sum(self.w**2) for i in range(len(y))])\n",
    "        #print([-np.log(output[i][int(y[i])]) for i in range(len(y))][:5])       \n",
    "        return loss\n",
    "    \n",
    "    def predict(self, X):\n",
    "        net_input = self.net_input(X)\n",
    "        output = self.activation(net_input)\n",
    "        return np.argmax(output, 1) # 1 = row argmax\n",
    "    \n",
    "    def accuracy(self, X, y):\n",
    "        correct = [self.predict(X)[i] == int(y[i]) for i in range(len(y))]\n",
    "        #print([self.predict(X)[i] == int(y[i]) for i in range(len(y))][:5])\n",
    "        return sum(correct)/len(y) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=’s3’></a>\n",
    "\n",
    "## 3 Load data & Apply the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Car data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw data from csv file, which located in the same folder as this notebook.\n",
    "\n",
    "X_train_raw = pd.read_csv(\"dataset_files/car_X_train.csv\").to_numpy()\n",
    "y_train_raw = pd.read_csv(\"dataset_files/car_y_train.csv\").to_numpy()\n",
    "X_test_raw = pd.read_csv(\"dataset_files/car_X_test.csv\").to_numpy()\n",
    "y_test_raw = pd.read_csv(\"dataset_files/car_y_test.csv\").to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform str indicators in data to numeric classes\n",
    "x_dict = {\n",
    "    'vhigh' : 4, \n",
    "    'high' : 3,\n",
    "    'med' : 2,\n",
    "    'low' : 1, \n",
    "     \n",
    "    'small' : 1,\n",
    "    # 'med' : 2,\n",
    "    'big' : 3,\n",
    "    \n",
    "    # '2' : 2, \n",
    "    # '4' : 4,\n",
    "    'more' : 6, \n",
    "    \n",
    "    '2' : 2, \n",
    "    '3' : 3,\n",
    "    '4' : 4,\n",
    "    '5more' : 6,\n",
    "}\n",
    "\n",
    "y_dict = {\n",
    "    'acc':1, 'good':2, 'unacc':0, 'vgood':3\n",
    "}\n",
    "\n",
    "def transform_X(X):\n",
    "    for i in range(len(X)):\n",
    "        x = X[i]\n",
    "        X[i] = [x_dict[i] for i in x]\n",
    "    return X\n",
    "\n",
    "def transform_y(y):\n",
    "    return [[y_dict[row[0]]] for row in y]\n",
    "\n",
    "X_train = transform_X(X_train_raw)\n",
    "y_train = np.array(transform_y(y_train_raw), dtype=int)\n",
    "X_test = transform_X(X_test_raw)\n",
    "y_test = np.array(transform_y(y_test_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the model, and fit the training data\n",
    "model = LogisticRegressionMulti(learning_rate=0.05, n_iter=10, regularization_param=0.01,\n",
    "                regularization=2, validation=1000)\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test accuracy result\n",
    "model.accuracy(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iris data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from csv file, which located in the same folder as this notebook.\n",
    "\n",
    "X_train = pd.read_csv(\"dataset_files/iris_X_train.csv\").to_numpy()\n",
    "y_train = pd.read_csv(\"dataset_files/iris_y_train.csv\").to_numpy()\n",
    "X_test = pd.read_csv(\"dataset_files/iris_X_test.csv\").to_numpy()\n",
    "y_test = pd.read_csv(\"dataset_files/iris_y_test.csv\").to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the model, and fit the training data\n",
    "model = LogisticRegressionMulti(learning_rate=0.05, n_iter=100, regularization_param=0.01,\n",
    "                regularization=2, validation=80)\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test accuracy result\n",
    "model.accuracy(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=’s4’></a>\n",
    "\n",
    "## 4 Plotting the result for analysis\n",
    "\n",
    "The data set used in this section is Iris Data Set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# better including the validation set to analyse\n",
    "x = np.arange(model.n_iter)\n",
    "\n",
    "plt.plot(x, model.cost, label=\"training loss\")\n",
    "plt.plot(x, model.cost_val, label=\"validation loss\")\n",
    "\n",
    "plt.xlabel(\"n_iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(model.n_iter)\n",
    "\n",
    "plt.plot(x, model.accu, label=\"training accuracy\")\n",
    "plt.plot(x, model.accu_val, label=\"validation accuracy\")\n",
    "\n",
    "plt.xlabel(\"n_iteration\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=’s5’></a>\n",
    "\n",
    "## 5 Parameter Analysis\n",
    "\n",
    "The data set used in this section is Iris Data Set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = np.concatenate((X_train, X_test))\n",
    "y_ = np.concatenate((y_train, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Param: regularization = 0 (no regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegressionMulti(regularization=0, validation=100)\n",
    "\n",
    "model.fit(X_, y_)\n",
    "# better including the validation set to analyse\n",
    "x = np.arange(model.n_iter)\n",
    "\n",
    "plt.plot(x, model.cost, label=\"training loss\")\n",
    "plt.plot(x, model.cost_val, label=\"validation loss\")\n",
    "\n",
    "plt.xlabel(\"n_iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(x, model.accu, label=\"training accuracy\")\n",
    "plt.plot(x, model.accu_val, label=\"validation accuracy\")\n",
    "\n",
    "plt.xlabel(\"n_iteration\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Param: regularization = 1 (L1 regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegressionMulti(regularization_param=0.005, regularization=1, validation=100)\n",
    "\n",
    "model.fit(X_, y_)\n",
    "# better including the validation set to analyse\n",
    "x = np.arange(model.n_iter)\n",
    "\n",
    "plt.plot(x, model.cost, label=\"training loss\")\n",
    "plt.plot(x, model.cost_val, label=\"validation loss\")\n",
    "\n",
    "plt.xlabel(\"n_iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(x, model.accu, label=\"training accuracy\")\n",
    "plt.plot(x, model.accu_val, label=\"validation accuracy\")\n",
    "\n",
    "plt.xlabel(\"n_iteration\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Param: regularization = 2 (L2 regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegressionMulti(regularization=0, validation=100)\n",
    "\n",
    "model.fit(X_, y_)\n",
    "# better including the validation set to analyse\n",
    "x = np.arange(model.n_iter)\n",
    "\n",
    "plt.plot(x, model.cost, label=\"training loss\")\n",
    "plt.plot(x, model.cost_val, label=\"validation loss\")\n",
    "\n",
    "plt.xlabel(\"n_iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(x, model.accu, label=\"training accuracy\")\n",
    "plt.plot(x, model.accu_val, label=\"validation accuracy\")\n",
    "\n",
    "plt.xlabel(\"n_iteration\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
